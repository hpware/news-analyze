# Scraping line today home

This took me some time, but they use a fancy system for pulling news data.

## Main endpoint
For local Taiwan news they use this url: https://today.line.me/_next/data/v1/tw/v3/tab/domestic.json?tabs=domestic

From the _next? I thought that is static? I mean it maybe is, it is just providing with the URLs that the client will be fetching to the server, which is a bit fun.

Here is a JSON snippet:
```json
{
  "id": "682b0cef1b1269f8dec93e60",
  "type": "HIGHLIGHT",
  "containerStyle": "Header",
  "name": "åœ‹å…§è©±é¡Œï¼šæ–°åŒ—é‡å¤§è»Šç¦",
  "source": "LISTING",
  "header": {
    "title": "æ–°åŒ—é‡å¤§æ­»å‚·è»Šç¦",
    "hasCompositeTitle": false,
    "subTitle": "ä¸€è¼›å°å®¢è»Š19æ—¥ä¸‹åˆæ’ä¸Šæ”¾å­¸äººç¾¤ï¼Œé€ æˆå¤šåå­¸ç«¥ã€å¤§äººé€é†«ï¼Œè‡³å°‘3æ­»10å¤šå‚·ï¼Œè‚‡äº‹çš„78æ­²ç”·å­ç•¶å ´æ˜è¿·ã€‚"
  },
  "listings": [
    {
      "id": "1feef7d2-3acc-495d-becd-3ef4de6a92ce",
      "offset": 0,
      "length": 10
    }
  ]
},
```

We can ignore everything else, other than the strange UUID in the json. Well, this is the key we need to fetch their api ğŸ¤©

## Fetch news URLs

Here is the fancy URL:
`https://today.line.me/api/v6/listings/{the-uuid-you-got-in-the-listings-json-file}/?country=tw&offset=0&length=24`

This api can be used for fetching the news from them, however, there is an issue, the max length is only just 24 (yes, I tried it only can return 24 when requesting for 1000)


And viewing the JSON, oh would you look at that.
```JSON
{
  "id": "262862833",
  "title": "æ´¾é§èŠ¬è˜­é­ç™½å§”æ‰¯ç„¦æ…®ç—‡ æ—æ˜¶ä½ç¾èº«å–Šè©±",
  "publisher": "å¤ªå ±",
  "publisherId": "101366",
  "publishTimeUnix": 1747670221000,
  "contentType": "GENERAL",
  "thumbnail": {
    "type": "IMAGE",
    "hash": "0hvoq7de5NKUBMTjcMHM5WF3QYJTF_KDNJbixudj4ddXJnYm4ecX16Iz0edWwydjsTbH9vdm5IJ3EyKjtBeA"
  },
  "url": {
    "hash": "8nlkYeV"
  },
  "categoryId": 100262,
  "categoryName": "åœ‹å…§",
  "shortDescription": "å‰ç«‹å§”æ—æ˜¶ä½ï¼ˆå³äºŒï¼‰å°‡å‡ºä»»é§èŠ¬è˜­ä»£è¡¨ï¼Œæ°‘çœ¾é»¨ç«‹å§”æ—æ†¶å›å»è³ªç–‘ç½¹æ‚£ç„¦æ…®ç—‡ä¸é©åˆå»åŒ—æ­ã€‚ç¿»æ”ç•«é¢å‰ç«‹å§”æ—æ˜¶ä½å°‡æ¥ä»»é§èŠ¬è˜­ä»£è¡¨ï¼Œæ°‘çœ¾é»¨ç«‹å§”æ—æ†¶å›ä»Šï¼ˆ5/19ï¼‰è³ªè©¢æŒ‡å‡ºï¼Œæ—æ—æ˜¶ä½æ›¾æ‚£ç„¦æ…®ç—‡ï¼ŒåŒ—æ­åœ‹å®¶æ—¥å¸¸çŸ­ï¼Œç—…ç—‡å®¹æ˜“ç™¼ä½œï¼Œè³ªç–‘æ˜¯å¦é©åˆã€‚æ—æ˜¶ä½æ™šé–“ç¾èº«ç›´æ’­ç¯€ç›®ï¼Œå‘ç—…å‹å–Šè©±ï¼Œè¦å°è‡ªå·±æœ‰ä¿¡å¿ƒï¼Œã€Œçµ•å°å¯ä»¥å›å¾©åˆ°æ­£å¸¸ç”Ÿæ´»ï¼ŒåŒ…æ‹¬å·¥ä½œã€ã€‚æ—æ†¶å›æŒ‡å‡ºï¼Œ1990å¹´èŠ¬è˜­æ˜¯å…¨çƒè‡ªæ®ºç‡æœ€é«˜åœ‹å®¶ï¼Œè€Œä¸”åŒ—æ­åœ‹å®¶çš„æ—¥ç…§å¾ˆçŸ­ï¼Œç—…ç—‡å®¹æ˜“ç™¼ä½œ..."
},
```
The url hash is just what we needed to use my scraper :D

You can query it by using: https://news.yuanhau.com/api/news/get/lt/8nlkYeV (Also videos are in the list, so avoid that) or just try this  https://today.line.me/tw/v2/article/8nlkYeV

and that's it, I've bypassed Line's attempt to block people like me. :)
